To compare different algorithms easier, I define that
Efficiency = Total Used Memory Size / Total Request Memory Size
and I use the result of testsuite/5.trace for comparision.

To measure preciser latencies, I used a high-resolution(nanosecond) timer in Linux, which is called 
clock_gettime() in the code.


Basic Points:

(1) Resourcce Map

i. Efficiency
Best = 98.96%
Worst = 0.001%
Average = 68.37%

ii. Latency(nanosecond)
				Best		Worst		Average
KMA_MALLOC		28			3914349		4359
KMA_FREE		30			1056799		4549

iii. Design
In my resource map implementation, I choose First-Fit as my policy, it will traverse the free list
until it finds a fit block for the request. And when a block is required to be free, it will traverse
the free list until it finds a place matching its address.

It will dynamically get some pages for more list items which will be added to the free list when being
free. In my implementation, it will onlu return pages to the page-level allocator when the last request
has been processed.

I don't use the free block itself as a list item. I allocate some pages for these list items instead.
After a block of memory is freed, I append a list item which contains the start address and the size to
the free list, and coalesce the adjacent free blocks if possible.

iv. Explanation
Malloc and free could be very quick when the free list is still small, but it will slow down as the size
of free list grows. And when the list items are run out, it will allocate another page to append all the
list item in this page to the unused item list from which it can distribute the list items when needed.
So the worst latency could be very large.

And because Resource Map never return the pages to the page-level allocator before the test is finished, so
the average efficiency is much lower than the best ratio.


(2) Buddy System

i. Efficiency
Best  = 71.40%
Worst  = 0.15%
Average  = 64.69%

ii. Latency(nanosecond)
				Best		Worst		Average
KMA_MALLOC		31			3885793		123
KMA_FREE		34			991815		103

iii. Design
In my implementation of Buddy system, I use 32 bytes as the smallest memory block size. And I do a lot 
of bit manipulation in this allocator, such as set_block_used, set_block_unused, and check_buddy_free.
To accelerate the process of finding corresponding page, I use a page map which could get the information
of the specified page by just looking up in a table. I also allocate some pages for the list items which 
will be used to manage the page information. And I associate the bitmaps and pages dynamically, because some
page doesn't need bitmap at all, for example the pages used to store control information, and this makes 
the allocator more efficient.

Because of the existence of the request of size less than 32 bytes, I must deal with this small request, I
choose to return the unused list item which can store the information of page for the request asking for
less than 16 bytes. And this optimization makes the allocator have less fragments, which means that it could
be more efficient again.

iv. Explanation
As we can see from the statistics, Buddy system has much lower latency than Resource Map, while lower
utilizaton ratio than Resource Map because of the round up operation in Buddy system.

Since I allocate separated pages for list items, and initializing them in one time, the worst latency of 
kma_malloc is also very high. But this kind of allocation is really rare, so the average latency is much better.

Extra Points:

(1) SVR4 Lazy Buddy

i. Efficiency
Best  = 71.50%
Worst  = 0.002%
Average  = 62.47%

ii. Latency(nanosecond)
				Best		Worst		Average
KMA_MALLOC		43			3837888		136
KMA_FREE		37			1116976		112

iii. Design
For the lazy buddy, I implemented it by reusing the source code of Buddy system I have implemented. So in 
this implementation, I only need to change the code in get_free_block and put_free_block, to follow the lazy 
policy asked by SVR4 Lazy Buddy algorithm. Another modification is to add a new field to each free list to
record the respective SLACK value which will be used in put_free_block to determine if the further coalescing
is needed.

iv. Explanation
Because of the almost same source code architecture with Buddy system, the latencies are almost the same. And
it also has the same reason(separated pages for list items and initialization is done in one time) for why 
the worst latency is so high.

(2) Power-of-two Free List

i. Efficiency
Best  = 70.53%
Worst  = 0.001%
Average  = 56.07%

ii. Latency(nanosecond)
				Best		Worst		Average
KMA_MALLOC		34			3795693		184
KMA_FREE		24			1084155		47

iii. Design
I implemented two versions of this allocator, one uses 'size' passed into the kma_free function, and the
other ignore the 'size' argument. By default, it will be compiled without using 'size'. I used separated 
pages for list items which will be used to manage the page information.

iv. Explanation
The worst latency is high because I initialize all the list items in each page in one time. The average
latency of kma_free is much lower than Buddy and Lazy Buddy because this allocator only append the free 
block to the corresponding free list instead of trying to coalesce the free blocks.

The best utilization ratio is almost the same as Buddy system and Lazy Buddy because they all use roud
up to get block size. Power-of-two Free List will never return pages to the page-level allocator until 
all the requests have been issued. And this makes this allocator's average utilization ratio is much 
lower than Buddy and Lazy Buddy.

(3) McKusick-Karels

i. Efficiency
Best  = 71.68%
Worst  = 0.001%
Average Effiency = 57.20%

ii. Latency(nanosecond)
				Best		Worst		Average
KMA_MALLOC		25			3986018		108
KMA_FREE		32			1055896		92

iii. Design
I reuse the source code framework of Power-of-two Free List allocator. The modification is that one page
could only have the blocks with the same size. which reduces the fragments. And I also use the page map
to accelerate the process of finding corresponding page.

iv. Explanation
As mentioned above, the worst latency is caused by doing all the initialization work in one time. This
allocator's average kma_free latency is about twice of Power-of-two Free List because this allocator need 
to figure out which page the return pointer is located on, so that it could append the freed block to the 
correct free list.






Author: Yang Yang (yangyang2016@u.northwestern.edu)
